{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# used to create the retrieval tool\n",
    "from langchain.agents.agent_toolkits import create_retriever_tool\n",
    "\n",
    "# used to create the memory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# used to create the prompt template\n",
    "from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "# used to create the agent executor\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve API key\n",
    "#os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  \n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# load PDF documents using PyMuPDF\n",
    "loader = DirectoryLoader('content/', glob=\"**/*.pdf\", show_progress=True, loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk pdf texts and create Chroma vector db\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=100)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "db = Chroma.from_documents(documents, OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"mmr\")\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"search_deep_learning_textbooks\",\n",
    "    \"Searches and returns documents regarding deep learning and NLP\",\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_key = \"history\"\n",
    "memory = ConversationBufferMemory(memory_key=memory_key, return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_style = \"Visual: Bullet Points\"\n",
    "\n",
    "system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"You are a tutor for LIGN 167, a deep learning and NLP course at UCSD, with immense knowledge and experience in the field.\"\n",
    "            \"Answer students' questions based on your knowledge and conversation history. Do not make up answers.\"\n",
    "            \"If you do not know the answer to a question, just say \\'I don't know\\'.\"\n",
    "            \"If asked a question not relevant to deep learning or NLP, just say \\'I cannot answer your question\\'.\"\n",
    "            \"Tailor your response to match a \" + learning_style + \" learning style.\"\n",
    "        )\n",
    ")\n",
    "\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=system_message,\n",
    "        extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0, model = \"gpt-4-1106-preview\")\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Bob! How can I assist you with deep learning or NLP today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"hi, im bob\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bob. If you have any questions related to deep learning or NLP, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"what is my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m- **MLP**: Multi-Layer Perceptron\n",
      "- **Type**: Artificial Neural Network (ANN)\n",
      "- **Architecture**: \n",
      "  - Input layer\n",
      "  - One or more hidden layers\n",
      "  - Output layer\n",
      "- **Connections**: Fully connected (each neuron to every neuron in the next layer)\n",
      "- **Data Flow**: Feedforward (no cycles or loops in the network)\n",
      "- **Activation Function**: Non-linear (e.g., ReLU, sigmoid, tanh)\n",
      "- **Learning**: Supervised (uses backpropagation)\n",
      "- **Purpose**: Classification, regression (non-sequential data)\n",
      "- **Limitation**: Cannot process sequential data as RNNs do\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"what is a MLP?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m- **MLP vs. RNN**:\n",
      "\n",
      "1. **Architecture**:\n",
      "   - MLP: Feedforward, no cycles\n",
      "   - RNN: Recurrent, with cycles allowing information to persist\n",
      "\n",
      "2. **Data Flow**:\n",
      "   - MLP: One-way from input to output\n",
      "   - RNN: Loops in the network enable sequence processing\n",
      "\n",
      "3. **Temporal Dynamics**:\n",
      "   - MLP: Treats each input independently\n",
      "   - RNN: Maintains internal state for sequence dependency\n",
      "\n",
      "4. **Use Cases**:\n",
      "   - MLP: Static input-output mapping (e.g., image classification)\n",
      "   - RNN: Sequential data (e.g., time series, language modeling)\n",
      "\n",
      "5. **Memory**:\n",
      "   - MLP: No memory of past inputs\n",
      "   - RNN: Memory through recurrent connections\n",
      "\n",
      "6. **Training**:\n",
      "   - MLP: Generally simpler, backpropagation\n",
      "   - RNN: More complex, backpropagation through time (BPTT)\n",
      "\n",
      "7. **Challenges**:\n",
      "   - MLP: May struggle with complex feature hierarchies\n",
      "   - RNN: Vanishing and exploding gradient problems\n",
      "\n",
      "8. **Variants**:\n",
      "   - MLP: Fewer variants\n",
      "   - RNN: Advanced variants like LSTM, GRU for long-term dependencies\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'- **MLP vs. RNN**:\\n\\n1. **Architecture**:\\n   - MLP: Feedforward, no cycles\\n   - RNN: Recurrent, with cycles allowing information to persist\\n\\n2. **Data Flow**:\\n   - MLP: One-way from input to output\\n   - RNN: Loops in the network enable sequence processing\\n\\n3. **Temporal Dynamics**:\\n   - MLP: Treats each input independently\\n   - RNN: Maintains internal state for sequence dependency\\n\\n4. **Use Cases**:\\n   - MLP: Static input-output mapping (e.g., image classification)\\n   - RNN: Sequential data (e.g., time series, language modeling)\\n\\n5. **Memory**:\\n   - MLP: No memory of past inputs\\n   - RNN: Memory through recurrent connections\\n\\n6. **Training**:\\n   - MLP: Generally simpler, backpropagation\\n   - RNN: More complex, backpropagation through time (BPTT)\\n\\n7. **Challenges**:\\n   - MLP: May struggle with complex feature hierarchies\\n   - RNN: Vanishing and exploding gradient problems\\n\\n8. **Variants**:\\n   - MLP: Fewer variants\\n   - RNN: Advanced variants like LSTM, GRU for long-term dependencies'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"how does it differ from an RNN?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI cannot answer your question.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent_executor({\"input\": \"what date was UCSD founded?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' agent = initialize_agent(\\n    tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory, verbose=True\\n) '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer')\n",
    "\n",
    "agent = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever(search_type=\"mmr\"), memory=memory, verbose=True\n",
    ")\n",
    "\n",
    "\"\"\" agent = initialize_agent(\n",
    "    tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory, verbose=True\n",
    ") \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
